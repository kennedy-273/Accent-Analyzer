import streamlit as st
import requests
import tempfile
import os
import subprocess
import speech_recognition as sr
from pydub import AudioSegment
import numpy as np
from moviepy.editor import AudioFileClip
import re
from urllib.parse import urlparse
import nltk
from collections import Counter
import time

# Download necessary NLTK data
try:
    nltk.data.find('tokenizers/punkt')
except LookupError:
    nltk.download('punkt')

st.set_page_config(
    page_title="REM Waste - English Accent Analyzer",
    page_icon="üéôÔ∏è",
    layout="centered"
)

# Define accent characteristics and markers
ACCENT_FEATURES = {
    "American": {
        "phonetic_markers": ["r", "t", "√¶"],
        "vocabulary": ["guys", "awesome", "gonna", "wanna", "y'all", "totally"],
        "phrases": ["you know", "like", "kind of"],
        "description": "American English typically has a rhotic accent (pronounced 'r' sounds), flapped 't' sounds between vowels, and distinctive vowel sounds."
    },
    "British": {
        "phonetic_markers": ["…ëÀê", "…í", " å"],
        "vocabulary": ["brilliant", "cheers", "mate", "proper", "reckon", "quite"],
        "phrases": ["sort of", "as it were", "rather"],
        "description": "British English often features non-rhotic pronunciation (dropping 'r' sounds unless followed by vowels), distinctive 'o' sounds, and t-glottalization."
    },
    "Australian": {
        "phonetic_markers": ["a…™", "e…™", "…ô ä"],
        "vocabulary": ["mate", "no worries", "arvo", "heaps", "reckon", "fair dinkum"],
        "phrases": ["how ya going", "too easy", "good on ya"],
        "description": "Australian English has distinctive diphthongs, a nasal quality, and rising intonation patterns with certain vowel shifts."
    },
    "Indian": {
        "phonetic_markers": [" à", "…ñ", "…≥"],
        "vocabulary": ["actually", "only", "itself", "prepone", "doing"],
        "phrases": ["the same", "like that only", "what to do"],
        "description": "Indian English often features retroflex consonants, rhythmic patterns influenced by native languages, and distinctive stress patterns."
    },
    "Canadian": {
        "phonetic_markers": ["o ä", "a ä", "a…™"],
        "vocabulary": ["eh", "toque", "loonie", "double-double", "washroom"],
        "phrases": ["for sure", "sorry", "about"],
        "description": "Canadian English combines features of American and British English with 'Canadian raising' of certain diphthongs and distinctive vocabulary."
    }
}

def download_video(url):
    """Download video from URL and save to temporary file"""
    try:
        # Parse URL to handle different sources
        parsed_url = urlparse(url)
        
        # Create temporary file with appropriate extension
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
        video_path = temp_file.name
        
        # Add headers to mimic a browser request
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        # Direct download approach
        st.info(f"Downloading video from: {url}")
        response = requests.get(url, stream=True, headers=headers, timeout=30)
        
        if response.status_code == 200:
            total_size = int(response.headers.get('content-length', 0))
            progress_bar = st.progress(0)
            downloaded = 0
            
            with open(video_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        downloaded += len(chunk)
                        if total_size > 0:
                            progress = downloaded / total_size
                            progress_bar.progress(progress)
                        
            progress_bar.empty()
            st.success("Video downloaded successfully!")
            return video_path
        else:
            st.error(f"Failed to download video: HTTP {response.status_code}")
            st.write("This might be due to:")
            st.write("- The URL is not accessible")
            st.write("- The server blocks direct downloads") 
            st.write("- The URL has expired or is invalid")
            return None
                
    except requests.exceptions.Timeout:
        st.error("Download timed out. The video might be too large or the server is slow.")
        return None
    except requests.exceptions.RequestException as e:
        st.error(f"Network error downloading video: {str(e)}")
        return None
    except Exception as e:
        st.error(f"Error downloading video: {str(e)}")
        return None

def extract_audio(video_path):
    """Extract audio from video file"""
    try:
        # Create temporary file for audio
        temp_audio = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
        audio_path = temp_audio.name
        
        # Use moviepy to extract audio
        audio_clip = AudioFileClip(video_path)
        audio_clip.write_audiofile(audio_path, logger=None)
        audio_clip.close()
        
        return audio_path
    except Exception as e:
        st.error(f"Error extracting audio: {str(e)}")
        return None

def transcribe_audio(audio_path):
    """Transcribe audio to text using speech recognition"""
    try:
        # Initialize recognizer
        r = sr.Recognizer()
        
        # Load audio file
        with sr.AudioFile(audio_path) as source:
            audio_data = r.record(source)
            
        # Transcribe using Google's speech recognition
        text = r.recognize_google(audio_data)
        return text
    except sr.UnknownValueError:
        st.error("Speech recognition could not understand the audio")
        return None
    except sr.RequestError as e:
        st.error(f"Could not request results from speech recognition service: {e}")
        return None
    except Exception as e:
        st.error(f"Error transcribing audio: {str(e)}")
        return None

def analyze_accent(text):
    """Analyze the accent based on text transcription"""
    if not text:
        return None, 0, ""
    
    text = text.lower()
    words = nltk.word_tokenize(text)
    
    # Calculate scores for each accent
    scores = {}
    for accent, features in ACCENT_FEATURES.items():
        score = 0
        
        # Check for vocabulary matches
        vocab_count = sum(1 for word in words if word in features["vocabulary"])
        score += vocab_count * 5  # Weight vocabulary higher
        
        # Check for phrases
        phrase_count = sum(1 for phrase in features["phrases"] if phrase in text)
        score += phrase_count * 8  # Weight phrases higher
        
        # Simple phonetic analysis (crude approximation)
        for marker in features["phonetic_markers"]:
            if marker in text:
                score += 3
        
        scores[accent] = score
    
    # Normalize scores if we have any matches
    max_score = max(scores.values()) if scores else 0
    if max_score > 0:
        # Get the accent with the highest score
        detected_accent = max(scores, key=scores.get)
        
        # Calculate confidence (0-100%)
        total_possible = 100  # Theoretical maximum
        confidence = min(scores[detected_accent] / total_possible * 100, 100)
        
        # For demo purposes, ensure we have at least some confidence
        confidence = max(confidence, 30)
        
        # Add slight randomization for demo purposes
        confidence = min(confidence + np.random.uniform(-10, 20), 100)
        
        explanation = ACCENT_FEATURES[detected_accent]["description"]
        
        return detected_accent, confidence, explanation
    else:
        return "Unknown", 0, "Could not detect distinctive accent features."

def cleanup(file_paths):
    """Clean up temporary files"""
    for path in file_paths:
        if path and os.path.exists(path):
            try:
                os.unlink(path)
            except:
                pass

def main():
    st.title("üéôÔ∏è English Accent Analyzer")
    st.write("Upload a video interview to analyze the speaker's English accent")
    
    # Input field for video URL
    video_url = st.text_input("Enter video URL (MP4 link):", "")
    
    # Provide some sample URLs for testing
    st.write("**Sample test URLs (copy and paste above):**")
    sample_urls = [
        "https://sample-videos.com/zip/10/mp4/SampleVideo_1280x720_1mb.mp4",
        "https://commondatastorage.googleapis.com/gtv-videos-bucket/sample/BigBuckBunny.mp4",
        "https://www.learningcontainer.com/wp-content/uploads/2020/05/sample-mp4-file.mp4"
    ]
    
    for i, url in enumerate(sample_urls, 1):
        if st.button(f"Use Sample URL {i}", key=f"sample_{i}"):
            st.session_state['selected_url'] = url
            st.rerun()
    
    # Show selected URL
    if 'selected_url' in st.session_state:
        video_url = st.session_state['selected_url']
        st.info(f"Selected URL: {video_url}")
    
    # Option for demo data (simulated results)
    use_sample = st.checkbox("Use demo data instead (simulate processing)")
    
    # File upload option
    uploaded_file = st.file_uploader("Or upload a video file:", type=["mp4", "avi", "mov"])
    
    if st.button("Analyze Accent"):
        # Clear previous outputs
        if 'results' in st.session_state:
            del st.session_state['results']
        
        with st.spinner("Processing video..."):
            # Handle different input methods
            if use_sample:
                # Use pre-defined demo data
                time.sleep(2)  # Simulate processing
                st.session_state['results'] = {
                    'accent': "American",
                    'confidence': 87.5,
                    'explanation': ACCENT_FEATURES["American"]["description"]
                }
            elif uploaded_file:
                # Handle file upload - save to temp file
                temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
                temp_file.write(uploaded_file.getvalue())
                video_path = temp_file.name
                
                # Extract audio from video
                audio_path = extract_audio(video_path)
                
                if audio_path:
                    # Transcribe audio to text
                    text = transcribe_audio(audio_path)
                    
                    if text:
                        # Analyze accent
                        accent, confidence, explanation = analyze_accent(text)
                        st.session_state['results'] = {
                            'accent': accent,
                            'confidence': confidence,
                            'explanation': explanation,
                            'transcription': text
                        }
                    else:
                        st.error("Failed to transcribe audio")
                
                # Clean up temporary files
                cleanup([video_path, audio_path])
            elif video_url and video_url.strip():
                # Download video from URL
                video_path = download_video(video_url)
                
                if video_path:
                    # Extract audio from video
                    st.info("Extracting audio from video...")
                    audio_path = extract_audio(video_path)
                    
                    if audio_path:
                        # Transcribe audio to text
                        st.info("Transcribing audio to text...")
                        text = transcribe_audio(audio_path)
                        
                        if text:
                            # Analyze accent
                            st.info("Analyzing accent...")
                            accent, confidence, explanation = analyze_accent(text)
                            st.session_state['results'] = {
                                'accent': accent,
                                'confidence': confidence,
                                'explanation': explanation,
                                'transcription': text
                            }
                        else:
                            st.error("Failed to transcribe audio. This could be due to:")
                            st.write("- Poor audio quality")
                            st.write("- No speech detected in the video")
                            st.write("- Audio format not supported")
                    
                    # Clean up temporary files
                    cleanup([video_path, audio_path])
                else:
                    st.error("Failed to download video. Please try:")
                    st.write("1. A different video URL")
                    st.write("2. Checking if the URL is publicly accessible")
                    st.write("3. Using the demo data option for testing")
            else:
                st.warning("Please enter a video URL, upload a file, or use the demo data")
    
    # Display results
    if 'results' in st.session_state:
        results = st.session_state['results']
        
        st.success("Analysis complete!")
        
        st.subheader("Results")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric("Detected Accent", results['accent'])
        
        with col2:
            st.metric("English Confidence Score", f"{results['confidence']:.1f}%")
        
        st.subheader("Accent Characteristics")
        st.write(results['explanation'])
        
        if 'transcription' in results:
            with st.expander("Show Transcription"):
                st.write(results['transcription'])
        
        # Visualization
        if results['accent'] in ACCENT_FEATURES:
            st.subheader("Accent Details")
            
            # Create a bar chart for accent confidence
            accent_data = {
                'Accent': list(ACCENT_FEATURES.keys()),
                'Confidence': [results['confidence'] if accent == results['accent'] else 
                              max(0, np.random.normal(30, 10)) for accent in ACCENT_FEATURES]
            }
            
            # Display as bar chart
            st.bar_chart({accent: conf for accent, conf in zip(accent_data['Accent'], accent_data['Confidence'])})
            
            # Display vocabulary examples
            if results['accent'] in ACCENT_FEATURES:
                st.write("**Common vocabulary markers:**", ", ".join(ACCENT_FEATURES[results['accent']]["vocabulary"]))

if __name__ == "__main__":
    main()